<div align="center">

# Reason-Code: On-Device System 2 Reasoning Platform ğŸ¤–

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/docker-required-blue)](https://www.docker.com/)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

<br/>

<img src="assets/hero_banner.png" width="100%" alt="Reason-Code Banner" style="border-radius: 10px;">

<br/>

**Scaling Inference-time Compute for Code Generation on Edge Devices**

[**English**](#-english) | [**ä¸­æ–‡**](#-chinese)

---
</div>

<a id="-english"></a>

## ğŸ“– Abstract

Reason-Code is an experimental AI Agent platform designed to verify the Inference-time Scaling Laws on consumer-grade hardware. It transforms small-scale local LLMs (specifically Qwen-2.5-1.5B) into powerful reasoning engines by implementing System 2 thinking methodologies:Monte Carlo Tree Search (MCTS) for solution space exploration.Execution-based Reflexion for iterative self-correction.Unlike standard "System 1" generation (Greedy/Temperature sampling), Reason-Code treats code generation as a multi-step reasoning workflow. It features a Hybrid Model Router and a DAG-based Workflow Engine, explicitly optimized for Apple Silicon (M1/M2) architectures, achieving significant performance gains on complex benchmarks where baseline models fail.

## ğŸ—ï¸ System Architecture (v2.0)

The system is built on a modular Agentic Framework comprising three core subsystems:Hybrid Model Router: Dynamically routes tasks based on complexity. Simple tasks run locally on Qwen-1.5B (LoRA) for privacy and speed, while complex tasks can be routed to remote SOTA APIs (e.g., GPT-4).DAG Workflow Engine: A flexible orchestration engine that manages Tools, Reasoning Nodes, and Execution Sandboxes in a directed acyclic graph.Secure Sandbox: An ephemeral Docker-based environment that executes generated code, captures stderr, and provides feedback for the Reflexion module.
Workflow Diagram

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'edgeLabelBackground':'#ffffff', 'tertiaryColor': '#fff', 'clusterBkg': '#fafafa', 'clusterBorder': '#e0e0e0', 'lineColor': '#555'}}}%%
graph LR
    classDef default fill:#fff,stroke:#333,stroke-width:1px,rx:5,ry:5;
    classDef highlight fill:#E3F2FD,stroke:#1565C0,stroke-width:2px;

    User("User Query") --> Router{"Adaptive Router"}
    
    subgraph ModelLayer ["Model Layer"]
        direction TB
        Router -- "Simple" --> Local["Local Qwen-1.5B"]
        Router -- "Complex" --> Remote["Remote GPT-4"]
    end
    
    Local & Remote --> Orchestrator
    
    subgraph Workflow ["Workflow Engine (DAG)"]
        direction LR
        Orchestrator["Orchestrator"] --> ToolNode["Tool Execution"]
        Orchestrator --> ReasonNode["Reasoning (MCTS)"]:::highlight
        
        ToolNode -.-> ReasonNode
        
        subgraph Core ["System 2 Core"]
            direction TB
            ReasonNode --> Expansion["Expansion"]
            Expansion --> Evaluation["Evaluation"]
            Evaluation --> Sandbox["Docker Sandbox"]
            Sandbox -- "Stderr" --> Reflexion["Reflexion"]
            Reflexion -.-> Expansion
        end
    end
    
    Reflexion --> Output("Final Solution"):::highlight
```
## ğŸ“‚ Project Structure

A domain-driven design structure ensuring scalability and maintainability:
```Plaintext
src/reason_code/
â”œâ”€â”€ agent/                  # Core Reasoning Algorithms (MCTS, Reflexion)
â”œâ”€â”€ workflow/               # Async DAG Execution Engine
â”œâ”€â”€ models/                 # Model Adapter Layer (Router, LoRA, OpenAI)
â”œâ”€â”€ executor/               # Docker Sandbox Manager
â”œâ”€â”€ tools/                  # Plugin System (@registry.register)
â””â”€â”€ utils/                  # Observability (OpenTelemetry, Logger)
```

## ğŸ“Š Performance & Experiments:

We evaluated the system on the HumanEval benchmark (Hard Subset: Tasks 90-110), specifically selecting problems that require multi-step logical reasoning.

**Hardware**: MacBook Pro (M1 Pro, 16GB RAM) **Model**: Qwen-2.5-Coder-1.5B-Instruct (LoRA Fine-tuned)

1. Benchmark Results

| Method | Search Strategy | Syntax Pass Rate | Logic Pass Rate (Pass@1) | Avg Latency |
| :--- | :--- | :---: | :---: | :---: | 
| Baseline | Zero-shot Greedy (n=1) | 100% | 40.0% (8/20) | 29.2s |
| Reason-Code | MCTS Search (n=10) | 100% | 50.0% (10/20) | 283.3s |

**Analysis**: In the challenging task range (HumanEval 90-110), Reason-Code achieved a **+25% relative improvement** (from 40% to 50%) in logical correctness.

**Note on Latency**: The increase in latency (283s vs 29s) reflects the deliberate **Inference-time** Compute trade-off. This time includes 10 full MCTS simulation paths, Docker container spin-up/tear-down cycles, and the Reflexion loops. We trade time for intelligence.

## 2. Edge-Native Optimization

The system maximizes hardware utilization on Apple Silicon. The screenshot below demonstrates **96% P-CPU utilization** and **30W power consumption** during parallel MCTS simulations, proving efficient asyncio thread pool management without OOM (Out of Memory).

<div align="center"> <img src="assets/resource_monitoring.png" width="50%" alt="Hardware Metrics" style="border-radius: 8px; border: 1px solid #ddd;"> </div>

## 3. Observability (Trace View)

Integrated with **Arize Phoenix** for full trace visualization. The trace below shows the agent autonomously fixing a syntax error via the MCTS expansion and Reflexion loop. Note the tree structure expanding on the left side.

<div align="center"> <img src="assets/trace_view.png" width="50%" alt="MCTS Trace" style="border-radius: 8px; border: 1px solid #ddd;"> </div>

## ğŸ› ï¸ Quick Start
### Prerequisites
* Python 3.10+
* Docker Desktop (Must be running for Sandbox execution)

## Installation
```Bash
git clone [https://github.com/Liz915/reason-code.git](https://github.com/Liz915/reason-code.git)
cd reason-code
pip install -r requirements.txt
```
### Usage
## 1. Run the Agent Workflow (Search + Code)
```Bash
python examples/demo_workflow.py
```
## 2. Run Benchmarks
```Bash
python benchmarks/humaneval_test.py
```
### ğŸ“š References
* **DeepSeek-Coder-V2**: *Breaking the Barrier of Closed-Source Models in Code Intelligence* ([Paper](https://arxiv.org/abs/2406.11931))
* **AlphaCode**: *Competition-Level Code Generation with AlphaCode* ([Paper](https://arxiv.org/abs/2203.07814))
* **Reflexion**: *Language Agents with Verbal Reinforcement Learning* ([Paper](https://arxiv.org/abs/2303.11366))
* **Qwen2.5**: *Qwen2.5 Technical Report* ([Paper](https://qwenlm.github.io/blog/qwen2.5/))

### ğŸ“„ License

MIT License Â© 2025 Zixu Li

---
<a id="-chinese"></a>

<div align="center">

# ğŸ¤– Reason-Code: ç«¯ä¾§ System 2 ä»£ç æ¨ç†å¹³å°

**æ¢ç´¢ç«¯ä¾§è®¾å¤‡ä¸Šçš„æ¨ç†æ—¶è®¡ç®— (Inference-time Compute) ä¸ Agent æ¶æ„**

<br/>

[English](#-english) | [ä¸­æ–‡](#-chinese)

</div>

### ğŸ“– é¡¹ç›®èƒŒæ™¯

**Reason-Code**æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„ AI Agent å¹³å°ã€‚å®ƒè‡´åŠ›äºéªŒè¯ **"æ¨ç†æ—¶è®¡ç®— (Inference-time Scaling)"** çš„å‡è®¾ã€‚é€šè¿‡é›†æˆ **MCTSï¼ˆè’™ç‰¹å¡æ´›æ ‘æœç´¢** å’Œ **Docker æ‰§è¡Œåé¦ˆ (Reflexion)**ï¼Œæœ¬é¡¹ç›®æˆåŠŸè®©ä»…æœ‰ 1.5B å‚æ•°çš„å°æ¨¡å‹åœ¨èµ„æºå—é™çš„ç«¯ä¾§è®¾å¤‡ï¼ˆå¦‚ MacBook M1ï¼‰ä¸Šå±•ç°å‡º System 2 çº§åˆ«çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚

### ğŸŒŸ æ ¸å¿ƒèƒ½åŠ› (v2.0)
* **âš™ï¸ DAG å·¥ä½œæµå¼•æ“**: æ”¯æŒå°†å·¥å…·è°ƒç”¨ã€æ¨ç†èŠ‚ç‚¹å’Œæ²™ç®±æ‰§è¡Œä¸²è”æˆçµæ´»çš„æœ‰å‘æ— ç¯å›¾æµæ°´çº¿ã€‚
* **ğŸ”€ æ™ºèƒ½æ¨¡å‹è·¯ç”±**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€åˆ‡æ¢æœ¬åœ°å°æ¨¡å‹ï¼ˆé™æœ¬/éšç§ï¼‰å’Œäº‘ç«¯å¤§æ¨¡å‹ï¼ˆå¢æ•ˆï¼‰ã€‚
* **ğŸ§© æ’ä»¶ç³»ç»Ÿ**: åŸºäºè£…é¥°å™¨çš„æ’ä»¶æ³¨å†Œæœºåˆ¶ï¼Œæ”¯æŒæœç´¢ã€è®¡ç®—å™¨ç­‰å¤–éƒ¨å·¥å…·æ‰©å±•ã€‚
* **ğŸ›¡ï¸ å®‰å…¨æ²™ç®±**: æ‰€æœ‰ä»£ç å‡åœ¨èµ„æºå—é™çš„ Docker å®¹å™¨ä¸­æ‰§è¡Œï¼Œç¡®ä¿å®¿ä¸»æœºå®‰å…¨ã€‚

### ğŸ—ï¸ æ ¸å¿ƒæ¶æ„ (v2.0)
```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'edgeLabelBackground':'#ffffff', 'tertiaryColor': '#fff', 'clusterBkg': '#fafafa', 'clusterBorder': '#e0e0e0', 'lineColor': '#555'}}}%%
graph LR
    %% èŠ‚ç‚¹æ ·å¼å®šä¹‰ï¼šåœ†è§’ã€é˜´å½±å¾®è°ƒ
    classDef default fill:#fff,stroke:#333,stroke-width:1px,rx:5,ry:5;
    classDef highlight fill:#E3F2FD,stroke:#1565C0,stroke-width:2px;
    
    User("ç”¨æˆ·è¾“å…¥") --> Router{"è‡ªé€‚åº”è·¯ç”±"}
    
    subgraph ModelLayer ["æ¨¡å‹å±‚ (Model Layer)"]
        direction TB
        Router -- "ä½å¤æ‚åº¦" --> Local["æœ¬åœ° Qwen-1.5B"]
        Router -- "é«˜å¤æ‚åº¦" --> Remote["è¿œç¨‹ GPT-4"]
    end
    
    %% å…³é”®è¿æ¥
    Local & Remote --> Orchestrator
    
    subgraph DAG ["å·¥ä½œæµå¼•æ“ (DAG)"]
        direction LR
        Orchestrator["å·¥ä½œæµç¼–æ’å™¨"] --> ToolNode["å·¥å…·æ‰§è¡Œ"]
        Orchestrator --> ReasonNode["æ¨ç†èŠ‚ç‚¹ (MCTS)"]:::highlight
        
        ToolNode -.-> ReasonNode
        
        subgraph Core ["System 2 æ ¸å¿ƒ"]
            direction TB
            ReasonNode --> Expansion["æ‰©å±•"]
            Expansion --> Evaluation["è¯„ä¼°"]
            Evaluation --> Sandbox["Docker æ²™ç®±"]
            Sandbox -- "æŠ¥é”™" --> Reflexion["åæ€ (Reflexion)"]
            Reflexion -.-> Expansion
        end
    end
    
    Reflexion --> Output("æœ€ç»ˆè§£"):::highlight
```
### ğŸ“Š æ€§èƒ½ä¸å¯è§‚æµ‹æ€§

## 1ã€å®éªŒæ•°æ®

æˆ‘ä»¬åœ¨ HumanEval éš¾é¢˜åŒºé—´ï¼ˆTask 90-110ï¼‰ä¸Šè¿›è¡Œäº†ä¸¥æ ¼çš„å¯¹æ¯”å®éªŒ
| æ–¹æ³• | ç­–ç•¥æè¿° | è¯­æ³•é€šè¿‡ç‡ | é€»è¾‘é€šè¿‡ç‡ (Pass@1) | å¹³å‡è€—æ—¶ (Avg Latency) |
| :--- | :--- | :---: | :---: | :---: |
| Baseline | Zero-shot Greedy ($n=1$) | 100% | 40.0% (8/20) | 29.23s |
| Reason-Code | MCTS æœç´¢ ($n=10$) | 100% | 50.0% (10/20) | 283.34s |

**ç»“è®º**: é€šè¿‡å¼•å…¥ System 2 æ¨ç†ï¼ŒReason-Code å®ç°äº† **25% çš„ç›¸å¯¹æ€§èƒ½æå‡**ã€‚

**å…³äºè€—æ—¶**: å¹³å‡è€—æ—¶ä» 29s å¢åŠ åˆ° 283sï¼Œè¿™æ˜¯ä¸ºäº†æ¢å–æ›´é«˜æ™ºèƒ½æ‰€ä»˜å‡ºçš„è®¡ç®—æˆæœ¬ï¼ˆInference-time Computeï¼‰ã€‚è¿™åŒ…å« 10 æ¬¡å®Œæ•´çš„æ¨¡æ‹Ÿè·¯å¾„ã€Docker å®¹å™¨çš„åå¤å¯åŠ¨ä¸é”€æ¯ä»¥åŠåæ€ä¿®æ­£çš„è¿‡ç¨‹ã€‚èµ„æºç›‘æ§

## 2. ç«¯ä¾§æé™ä¼˜åŒ– (Edge-Native Optimization)
é’ˆå¯¹ Apple Silicon ç»Ÿä¸€å†…å­˜æ¶æ„æ·±åº¦ä¼˜åŒ–ã€‚ä¸‹å›¾å±•ç¤ºäº†åœ¨ 10 å¹¶å‘ MCTS æœç´¢ä¸‹çš„ç¡¬ä»¶è´Ÿè½½ï¼šP-CPU åˆ©ç”¨ç‡é«˜è¾¾ 96%ï¼ŒåŠŸè€—ç¨³å®šåœ¨ 26W+ï¼Œè¯æ˜äº† asyncio çº¿ç¨‹æ± çš„é«˜æ•ˆè°ƒåº¦ã€‚

<div align="center"> <img src="assets/resource_monitoring.png" width="50%" alt="Hardware Metrics" style="border-radius: 8px; border: 1px solid #ddd;"> </div>

## 3. å…¨é“¾è·¯å¯è§‚æµ‹æ€§ (Observability)

é›†æˆ Arize Phoenix å¯è§†åŒ– Agent çš„æ€è€ƒè¿‡ç¨‹ã€‚ä¸‹å›¾å±•ç¤ºäº†ç³»ç»Ÿå¦‚ä½•é€šè¿‡ MCTS æ ‘æ‰©å±•ï¼ˆå·¦ä¾§æ ‘çŠ¶å›¾ï¼‰ï¼Œåˆ©ç”¨æ²™ç®±æŠ¥é”™ä¿¡æ¯è‡ªåŠ¨ä¿®å¤ä»£ç  bugã€‚

<div align="center"> <img src="assets/trace_view.png" width="50%" alt="Trace View" style="border-radius: 8px; border: 1px solid #ddd;"> </div>

### ğŸ› ï¸ å¿«é€Ÿå¼€å§‹
## 1. å®‰è£…ä¾èµ–
```Bash
git clone [https://github.com/Liz915/reason-code.git](https://github.com/Liz915/reason-code.git)
cd reason-code
pip install -r requirements.txt
```
## 2. è¿è¡Œå®Œæ•´å·¥ä½œæµæ¼”ç¤º
```Bash
python examples/demo_workflow.py
```
## 3. è¿è¡ŒåŸºå‡†æµ‹è¯•
```Bash
python benchmarks/humaneval_test.py
```
## ğŸ“š å‚è€ƒæ–‡çŒ®ä¸è‡´è°¢

æœ¬é¡¹ç›®åœ¨å®ç°è¿‡ç¨‹ä¸­å‚è€ƒäº†ä»¥ä¸‹ä»£ç ç”Ÿæˆä¸æ¨ç†é¢†åŸŸçš„ç»å…¸è®ºæ–‡ï¼Œç‰¹æ­¤è‡´è°¢ï¼š

* **DeepSeek-Coder-V2**: *Breaking the Barrier of Closed-Source Models in Code Intelligence* ([è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2406.11931))
    * *å‚è€ƒç‚¹ï¼šMCTS åœ¨ä»£ç ç”Ÿæˆä¸­çš„åº”ç”¨ä¸æ¨¡å‹èƒ½åŠ›çš„è¯„ä¼°æ ‡å‡†ã€‚*
* **AlphaCode**: *Competition-Level Code Generation with AlphaCode* ([è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2203.07814))
    * *å‚è€ƒç‚¹ï¼šå¤§è§„æ¨¡é‡‡æ ·ä¸è¿‡æ»¤ç­–ç•¥ (Generate & Filter)ã€‚*
* **Reflexion**: *Language Agents with Verbal Reinforcement Learning* ([è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2303.11366))
    * *å‚è€ƒç‚¹ï¼šåŸºäºæ‰§è¡Œåé¦ˆçš„è‡ªæˆ‘åæ€ä¸ä¿®æ­£æœºåˆ¶ã€‚*
* **Qwen2.5**: *Qwen2.5 Technical Report* ([å®˜æ–¹æŠ¥å‘Š](https://qwenlm.github.io/blog/qwen2.5/))
    * *å‚è€ƒç‚¹ï¼šä½œä¸ºæœ¬é¡¹ç›®çš„åŸºç¡€ç­–ç•¥ç½‘ç»œ (Policy Network)ã€‚*


## ğŸ“„ è®¸å¯è¯

MIT License Â© 2025 Zixu Li


